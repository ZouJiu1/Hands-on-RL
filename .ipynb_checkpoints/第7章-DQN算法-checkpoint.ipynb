{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OHoSU6uI-xIt"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import rl_utils\n",
    "'''\n",
    "https://zhuanlan.zhihu.com/p/656515516\n",
    "强化学习的两个主要组成部分就是：0、智能体或者大脑；1、环境。环境是给定的，也就是一般由openai提供的gym库，或者gymnasium这个库。这两个库提供了很多不同的强化学习环境，可以拿来调用的，上面的悬崖环境就在gymnasium库内的，gym库已经不再update了。\n",
    "智能体或者大脑：智能体根据策略或者大脑，根据环境给出的奖励reward，以及分析环境提供的状态state信息，进而给出下一步的动作action；智能体还需要能够拿到状态信息，像robot就有许许多多的传感器，来感知环境的状态信息的。\n",
    "环境：环境一般是连续的不离散的，环境需要根据智能体给出的动作action做出相应的改变，还需要给出相应的奖励reward，以及状态信息state，状态信息通常是需要智能体主动获取的，当然比较简单的环境可能就直接给出了状态信息，不需要智能体主动获取。\n",
    "一般环境是gymnasium库提供的内容，环境会负责step(action)前进一步的，每次根据动作前进一步或者执行一步，会返回next_state, reward, done, _，也就分别是 下一个状体、奖励、是否结束的。或者重置环境reset()。\n",
    "智能体是需要program的，也就是需要人工手动program，给出策略或者深度神经网络模拟大脑，每次从环境拿到状态信息state，以及reward奖励的，智能体根据奖励以及分析拿到的状态信息，做出决策的，也就是给出动作action。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TsptTKz6-xIv"
   },
   "outputs": [],
   "source": [
    "## 保存历史数据，采样历史数据，拿到历史数据\n",
    "class ReplayBuffer:\n",
    "    ''' 经验回放池 '''\n",
    "    def __init__(self, capacity): ## 容量的大小\n",
    "        self.buffer = collections.deque(maxlen=capacity)  # 队列,先进先出\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):  # 将数据加入buffer\n",
    "        self.buffer.append((state, action, reward, next_state, done))  ## 加入到队列内部\n",
    "\n",
    "    def sample(self, batch_size):  # 从buffer中采样数据,数量为batch_size\n",
    "        transitions = random.sample(self.buffer, batch_size)  ## 随机采样的呢，拿到采样的历史数据\n",
    "        state, action, reward, next_state, done = zip(*transitions)  ## 使用zip来转置，也就是不同的自变量在不同的行\n",
    "        return np.array(state), action, reward, np.array(next_state), done  ## 状态、动作、奖励、下一个状态，是否结束的\n",
    "\n",
    "    def size(self):  # 目前buffer中数据的数量\n",
    "        return len(self.buffer)  ##  返回历史数据的总长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_qO6koMR-xIw"
   },
   "outputs": [],
   "source": [
    "## 构造智能体agent的大脑，也就是输入状态，返回该状态下，每个动作的动作价值\n",
    "## 输入是状态的，也就是 (车子center-point的坐标，车子的速度，杆的竖直角度，杆的角速度)\n",
    "## 返回值应该是2 dim，\n",
    "class Qnet(torch.nn.Module):\n",
    "    ''' 只有一层隐藏层的Q网络 '''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)  ## full connect层1\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, action_dim) ## full connect层2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # 隐藏层使用ReLU激活函数\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wxZItCX4-xIw"
   },
   "outputs": [],
   "source": [
    "##  构造智能体的\n",
    "class DQN:\n",
    "    ''' DQN算法 '''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, learning_rate, gamma,\n",
    "                 epsilon, target_update, device):\n",
    "        self.action_dim = action_dim  ##  动作的dim\n",
    "        ## 实例化智能体的大脑\n",
    "        self.q_net = Qnet(state_dim, hidden_dim, self.action_dim).to(device)  # Q网络\n",
    "        # 目标网络\n",
    "        self.target_q_net = Qnet(state_dim, hidden_dim, self.action_dim).to(device)\n",
    "        # 使用Adam优化器\n",
    "        self.optimizer = torch.optim.Adam(self.q_net.parameters(), lr=learning_rate)\n",
    "        self.gamma = gamma  # 折扣因子\n",
    "        self.epsilon = epsilon  # epsilon-贪婪策略\n",
    "        self.target_update = target_update  # 目标网络更新频率\n",
    "        self.count = 0  # 计数器,记录更新次数\n",
    "        self.device = device\n",
    "\n",
    "    def take_action(self, state):  # epsilon-贪婪策略采取动作\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.randint(self.action_dim) ## 随机选择一个动作\n",
    "        else:\n",
    "            state = torch.tensor([state], dtype=torch.float).to(self.device) ## 状态\n",
    "            action = self.q_net(state).argmax().item()  ## 智能体的大脑，根据状态拿到动作价值，q_net返回值是每个动作的动作价值，然后拿到动作的\n",
    "        return action\n",
    "\n",
    "    ## 使用历史数据来训练智能体的大脑，两个大脑的，一个实时update做label，另一个延迟update做predict\n",
    "    '''\n",
    "    损失函数需要label和predict，但是强化学习是没有label的，所以需要人工构造label才行，DQN使用的构造方式是使用update步长不相同的两个Qnet，\n",
    "    update数量较多的Qnet来做label，数量较少的Qnet来做predict。所以label就是使用的newest update的Qnet。相当是两个人，一个学的时间长些，\n",
    "    一个学的时间短些，所以这个学习时间更长的人，可以当老师了，学习时间短的人，就只能当学生了。老师可以教导学生的。所以两个大脑模型Qnet，\n",
    "    一个做老师，一个是学生，也就是一个label另一个则是predict。这样就构造出了相应的label。\n",
    "    target_q_net使用下一个状态，然后Q-learning来predict当前(状态，动作)的动作价值，predict\n",
    "    q_net使用当前状态和动作，直接算出当前(状态，动作)的动作价值，label\n",
    "    '''\n",
    "    def update(self, transition_dict):\n",
    "        ## 初始化 状态、动作、奖励、下一个状态、是否结束的\n",
    "        states = torch.tensor(transition_dict['states'], dtype=torch.float).to(self.device)\n",
    "        actions = torch.tensor(transition_dict['actions']).view(-1, 1).to(self.device)\n",
    "        rewards = torch.tensor(transition_dict['rewards'], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "        next_states = torch.tensor(transition_dict['next_states'], dtype=torch.float).to(self.device)\n",
    "        dones = torch.tensor(transition_dict['dones'], dtype=torch.float).view(-1, 1).to(self.device)\n",
    "\n",
    "        ## target, 因该网络实时update，所以可以看作是真实值，也就是监督学习内的label，而目标网络延迟很多，目标网络的输出可以看作predict\n",
    "        ## “真实”label，q_net输入当前的状态，返回值是当前状态下每个动作的动作价值，所以gather以后拿到的是：当前(状态和动作)对应的动作价值\n",
    "        q_values = self.q_net(states).gather(1, actions)  # Q值\n",
    "        # 下个状态的最大Q值，延迟网络的输出\n",
    "        ## 可以看作是predict，输入是下一个状态，返回值是下一个状态所有动作的动作价值内的最大值\n",
    "        ## 用来算当前(状态和动作)下的动作价值\n",
    "        max_next_q_values = self.target_q_net(next_states).max(1)[0].view(-1, 1)\n",
    "        ## Q-learning algorithm，算出的是当前(状态和动作)的动作价值\n",
    "        q_targets = rewards + self.gamma * max_next_q_values * (1 - dones)  # TD误差目标\n",
    "        ## q_net的truth label 和 target_q_net的predict，算损失用来反向传播\n",
    "        ## 也就是两个网络算出来的（状态和动作）对应的动作价值，用MSE来算损失函数的呢\n",
    "        dqn_loss = torch.mean(F.mse_loss(q_values, q_targets))  # 均方误差损失函数\n",
    "        self.optimizer.zero_grad()  # PyTorch中默认梯度会累积,这里需要显式将梯度置为0\n",
    "        dqn_loss.backward()   ##  反向传播求出梯度\n",
    "        self.optimizer.step() ##  使用累加的梯度来update参数\n",
    "\n",
    "        if self.count % self.target_update == 0:    ##  达到了给定的步长，复制最newest的参数给target_q_net网络，q_net是label，target_q_net是predict\n",
    "            self.target_q_net.load_state_dict(self.q_net.state_dict())  # 更新目标网络\n",
    "        self.count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97226,
     "status": "ok",
     "timestamp": 1649955480772,
     "user": {
      "displayName": "Sam Lu",
      "userId": "15789059763790170725"
     },
     "user_tz": -480
    },
    "id": "acJ1letz-xIx",
    "outputId": "26487c0d-c504-44d6-eb15-5fb137b9488f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 0:   0%|                                                                              | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 4 at dim 2 (got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m---> 32\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     34\u001b[0m     replay_buffer\u001b[38;5;241m.\u001b[39madd(state, action, reward, next_state, done)\n",
      "Cell \u001b[1;32mIn[18], line 24\u001b[0m, in \u001b[0;36mDQN.take_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     22\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dim)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     25\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net(state)\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 4 at dim 2 (got 0)"
     ]
    }
   ],
   "source": [
    "lr = 2e-3\n",
    "num_episodes = 500\n",
    "hidden_dim = 128\n",
    "gamma = 0.98\n",
    "epsilon = 0.01\n",
    "target_update = 10\n",
    "buffer_size = 10000\n",
    "minimal_size = 500\n",
    "batch_size = 64\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "env_name = 'CartPole-v0'\n",
    "env = gym.make(env_name)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "# env.seed(0)\n",
    "torch.manual_seed(0)\n",
    "replay_buffer = ReplayBuffer(buffer_size)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "agent = DQN(state_dim, hidden_dim, action_dim, lr, gamma, epsilon,\n",
    "            target_update, device)\n",
    "\n",
    "return_list = []\n",
    "for i in range(10):\n",
    "    ## 训练的次数是\n",
    "    with tqdm(total=int(num_episodes / 10), desc='Iteration %d' % i) as pbar:\n",
    "        for i_episode in range(int(num_episodes / 10)):\n",
    "            episode_return = 0   ## 累积的奖励\n",
    "            state = env.reset()  ## 环境随机重置的\n",
    "            if len(state)!=2*2:\n",
    "                state = state[0]\n",
    "            done = False ## 是否结束的\n",
    "            while not done:\n",
    "                action = agent.take_action(state) ## 拿到动作价值最大的动作，取值可选值是：0 或者 1\n",
    "                ## 环境根据动作，前进一步的，拿到下一个状态，奖励，是否终止，是否步长太长，info\n",
    "                next_state, reward, terminated, truncated, info = env.step(action)  \n",
    "                done = terminated | truncated  ## 终止或者步长太长，都会导致已经结束\n",
    "                ## 将状态、动作、奖励、下一个状态、是否结束，加入到缓冲池，也就是历史内，用来训练大脑网络的\n",
    "                replay_buffer.add(state, action, reward, next_state, done)\n",
    "                state = next_state   ## 下一个状态赋值到当前状态\n",
    "                episode_return += reward  ##累加奖励的\n",
    "                # 当buffer数据的数量超过一定值后,才进行Q网络训练\n",
    "                if replay_buffer.size() > minimal_size:         ## 不停的和环境交互，直到缓冲池内的历史数据大于一定的数量，再开始训练网络的\n",
    "                    ## 从缓冲池采样历史数据，用来训练大脑网络的\n",
    "                    b_s, b_a, b_r, b_ns, b_d = replay_buffer.sample(batch_size)\n",
    "                    transition_dict = {      ##  拿到的历史数据\n",
    "                        'states': b_s,\n",
    "                        'actions': b_a,\n",
    "                        'next_states': b_ns,\n",
    "                        'rewards': b_r,\n",
    "                        'dones': b_d\n",
    "                    }\n",
    "                    agent.update(transition_dict)  ## 训练大脑网络 q_net\n",
    "            return_list.append(episode_return)\n",
    "            if (i_episode + 1) % 10 == 0:\n",
    "                pbar.set_postfix({\n",
    "                    'episode':\n",
    "                    '%d' % (num_episodes / 10 * i + i_episode + 1),\n",
    "                    'return':\n",
    "                    '%.3f' % np.mean(return_list[-10:])\n",
    "                })\n",
    "            pbar.update(1)\n",
    "\n",
    "# Iteration 0: 100%|██████████| 50/50 [00:00<00:00, 764.86it/s, episode=50,\n",
    "# return=9.300]\n",
    "# Iteration 1: 100%|██████████| 50/50 [00:04<00:00, 10.66it/s, episode=100,\n",
    "# return=12.300]\n",
    "# Iteration 2: 100%|██████████| 50/50 [00:24<00:00,  2.05it/s, episode=150,\n",
    "# return=123.000]\n",
    "# Iteration 3: 100%|██████████| 50/50 [01:25<00:00,  1.71s/it, episode=200,\n",
    "# return=153.600]\n",
    "# Iteration 4: 100%|██████████| 50/50 [01:30<00:00,  1.80s/it, episode=250,\n",
    "# return=180.500]\n",
    "# Iteration 5: 100%|██████████| 50/50 [01:24<00:00,  1.68s/it, episode=300,\n",
    "# return=185.000]\n",
    "# Iteration 6: 100%|██████████| 50/50 [01:32<00:00,  1.85s/it, episode=350,\n",
    "# return=193.900]\n",
    "# Iteration 7: 100%|██████████| 50/50 [01:31<00:00,  1.84s/it, episode=400,\n",
    "# return=196.600]\n",
    "# Iteration 8: 100%|██████████| 50/50 [01:33<00:00,  1.88s/it, episode=450,\n",
    "# return=193.800]\n",
    "# Iteration 9: 100%|██████████| 50/50 [01:34<00:00,  1.88s/it, episode=500,\n",
    "# return=200.000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1649955495697,
     "user": {
      "displayName": "Sam Lu",
      "userId": "15789059763790170725"
     },
     "user_tz": -480
    },
    "id": "AFiCxG4W-xIy",
    "outputId": "b5610f6f-8df9-4156-ecb9-e8cb2901133c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDQN on \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(env_name))\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m----> 8\u001b[0m mv_return \u001b[38;5;241m=\u001b[39m \u001b[43mrl_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmoving_average\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(episodes_list, mv_return)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisodes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\access\\Hands-on-RL\\rl_utils.py:26\u001b[0m, in \u001b[0;36mmoving_average\u001b[1;34m(a, window_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m middle \u001b[38;5;241m=\u001b[39m (cumulative_sum[window_size:] \u001b[38;5;241m-\u001b[39m cumulative_sum[:\u001b[38;5;241m-\u001b[39mwindow_size]) \u001b[38;5;241m/\u001b[39m window_size\n\u001b[0;32m     25\u001b[0m r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, window_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m begin \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\n\u001b[0;32m     27\u001b[0m end \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mcumsum(a[:\u001b[38;5;241m-\u001b[39mwindow_size:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])[::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m r)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate((begin, middle, end))\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,) (4,) "
     ]
    }
   ],
   "source": [
    "episodes_list = list(range(len(return_list)))\n",
    "plt.plot(episodes_list, return_list)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('DQN on {}'.format(env_name))\n",
    "plt.show()\n",
    "\n",
    "mv_return = rl_utils.moving_average(return_list, 9)\n",
    "plt.plot(episodes_list, mv_return)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('DQN on {}'.format(env_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDk1DgrL-xIz"
   },
   "outputs": [],
   "source": [
    "class ConvolutionalQnet(torch.nn.Module):\n",
    "    ''' 加入卷积层的Q网络 '''\n",
    "    def __init__(self, action_dim, in_channels=4):\n",
    "        super(ConvolutionalQnet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = torch.nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.fc4 = torch.nn.Linear(7 * 7 * 64, 512)\n",
    "        self.head = torch.nn.Linear(512, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x / 255\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return self.head(x)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "第7章-DQN算法.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
